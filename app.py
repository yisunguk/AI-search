import streamlit as st
import os
import time
import uuid
from datetime import datetime, timedelta
from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions, generate_container_sas, ContainerSasPermissions
from azure.ai.translation.document import DocumentTranslationClient, DocumentTranslationInput, TranslationTarget
from azure.core.credentials import AzureKeyCredential
import urllib.parse
import requests

# Search Manager Import
from search_manager import AzureSearchManager

# Chat Manager Import  
from chat_manager import AzureOpenAIChatManager
from doc_intel_manager import DocumentIntelligenceManager
import excel_manager

# Authentication imports
from utils.auth_manager import AuthManager
from modules.login_page import render_login_page

# -----------------------------
# ì„¤ì • ë° ë¹„ë°€ ê´€ë¦¬
# -----------------------------
st.set_page_config(page_title="ì¸í…”ë¦¬ì „íŠ¸ ë‹¤íë¨¼íŠ¸", page_icon="ğŸ—ï¸", layout="centered")

# Custom CSS for larger tab labels
st.markdown("""
<style>
    /* Increase font size for tab labels */
    button[data-baseweb="tab"] {
        font-size: 20px !important;
    }
    button[data-baseweb="tab"] p {
        font-size: 20px !important;
        font-weight: 600 !important;
    }
</style>
""", unsafe_allow_html=True)

def get_secret(key):
    if key in st.secrets:
        return st.secrets[key]
    return os.environ.get(key)

# í•„ìˆ˜ ìê²© ì¦ëª…
# 1. Storage
STORAGE_CONN_STR = get_secret("AZURE_STORAGE_CONNECTION_STRING")
CONTAINER_NAME = get_secret("AZURE_BLOB_CONTAINER_NAME") or "blob-leesunguk"

# 2. Translator
TRANSLATOR_KEY = get_secret("AZURE_TRANSLATOR_KEY")
TRANSLATOR_ENDPOINT = get_secret("AZURE_TRANSLATOR_ENDPOINT")

# 3. Search
SEARCH_ENDPOINT = get_secret("AZURE_SEARCH_ENDPOINT")
SEARCH_KEY = get_secret("AZURE_SEARCH_KEY")
SEARCH_INDEX_NAME = get_secret("AZURE_SEARCH_INDEX_NAME") or "pdf-search-index"
SEARCH_INDEXER_NAME = "pdf-indexer"
SEARCH_DATASOURCE_NAME = "blob-datasource"

# 4. Azure OpenAI
AZURE_OPENAI_ENDPOINT = get_secret("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_KEY = get_secret("AZURE_OPENAI_KEY")
AZURE_OPENAI_DEPLOYMENT = get_secret("AZURE_OPENAI_DEPLOYMENT") or get_secret("AZURE_OPENAI_DEPLOYMENT_NAME")
AZURE_OPENAI_API_VERSION = get_secret("AZURE_OPENAI_API_VERSION")

# 5. Document Intelligence
AZURE_DOC_INTEL_ENDPOINT = get_secret("AZURE_DOC_INTEL_ENDPOINT")
AZURE_DOC_INTEL_KEY = get_secret("AZURE_DOC_INTEL_KEY")

# -----------------------------
# Azure í´ë¼ì´ì–¸íŠ¸ í—¬í¼
# -----------------------------
def get_blob_service_client():
    if not STORAGE_CONN_STR:
        st.error("Azure Storage Connection Stringì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    return BlobServiceClient.from_connection_string(STORAGE_CONN_STR)

def get_translation_client():
    if not TRANSLATOR_KEY or not TRANSLATOR_ENDPOINT:
        st.error("Azure Translator Key ë˜ëŠ” Endpointê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    return DocumentTranslationClient(TRANSLATOR_ENDPOINT, AzureKeyCredential(TRANSLATOR_KEY))

def get_search_manager():
    if not SEARCH_ENDPOINT or not SEARCH_KEY:
        st.error("Azure Search Endpoint ë˜ëŠ” Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    return AzureSearchManager(SEARCH_ENDPOINT, SEARCH_KEY, SEARCH_INDEX_NAME)

def get_chat_manager():
    if not AZURE_OPENAI_ENDPOINT or not AZURE_OPENAI_KEY:
        st.error("Azure OpenAI Endpoint ë˜ëŠ” Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    
    # Get search manager for Client-Side RAG
    search_manager = get_search_manager()
    
    return AzureOpenAIChatManager(
        endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=AZURE_OPENAI_KEY,
        deployment_name=AZURE_OPENAI_DEPLOYMENT,
        api_version=AZURE_OPENAI_API_VERSION,
        search_manager=search_manager,
        storage_connection_string=STORAGE_CONN_STR,
        container_name=CONTAINER_NAME
    )

def get_doc_intel_manager():
    if not AZURE_DOC_INTEL_ENDPOINT or not AZURE_DOC_INTEL_KEY:
        st.error("Azure Document Intelligence Endpoint ë˜ëŠ” Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    return DocumentIntelligenceManager(AZURE_DOC_INTEL_ENDPOINT, AZURE_DOC_INTEL_KEY)

def generate_sas_url(blob_service_client, container_name, blob_name=None, permission="r", expiry_hours=1):
    """
    Blob ë˜ëŠ” Containerì— ëŒ€í•œ SAS URL ìƒì„±
    blob_nameì´ ìˆìœ¼ë©´ Blob SAS, ì—†ìœ¼ë©´ Container SAS (Writeìš©)
    """
    import urllib.parse
    
    account_name = blob_service_client.account_name
    
    # Connection Stringìœ¼ë¡œ ìƒì„±ëœ ê²½ìš° credentialì€ dictì¼ ìˆ˜ ìˆìŒ
    if hasattr(blob_service_client.credential, 'account_key'):
        account_key = blob_service_client.credential.account_key
    else:
        account_key = blob_service_client.credential['account_key']
    
    # ì‹œê³„ ì˜¤ì°¨(Clock Skew) ë°©ì§€ë¥¼ ìœ„í•´ ì‹œì‘ ì‹œê°„ì„ 15ë¶„ ì „ìœ¼ë¡œ ì„¤ì •
    start = datetime.utcnow() - timedelta(minutes=15)
    expiry = datetime.utcnow() + timedelta(hours=expiry_hours)
    
    if blob_name:
        # Blob SAS ì‚¬ìš© (íŒŒì¼ ì§ì ‘ ì—´ê¸° ì§€ì›ì„ ìœ„í•´ content_disposition ì„¤ì •)
        import mimetypes
        content_type, _ = mimetypes.guess_type(blob_name)
        if not content_type:
            content_type = "application/octet-stream"
            
        # PDFëŠ” inline, ë‚˜ë¨¸ì§€ëŠ” attachment (ë˜ëŠ” ë¸Œë¼ìš°ì € ê¸°ë³¸ ë™ì‘)
        # ì—‘ì…€ ë“±ì€ ë¸Œë¼ìš°ì €ê°€ ì•Œì•„ì„œ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬í•¨
        content_disposition = "inline" if content_type == "application/pdf" else "attachment"

        sas_token = generate_blob_sas(
            account_name=account_name,
            container_name=container_name,
            blob_name=blob_name,
            account_key=account_key,
            permission=BlobSasPermissions(read=True),
            start=start,
            expiry=expiry,
            content_disposition=content_disposition, 
            content_type=content_type
        )
        
        base_url = f"https://{account_name}.blob.core.windows.net/{container_name}"
        encoded_blob_name = urllib.parse.quote(blob_name, safe='/')
        return f"{base_url}/{encoded_blob_name}?{sas_token}"
        
    else:
        # Container SAS ì‚¬ìš© (í´ë” ì‘ì—…ìš©)
        sas_token = generate_container_sas(
            account_name=account_name,
            container_name=container_name,
            account_key=account_key,
            permission=ContainerSasPermissions(write=True, list=True, read=True, delete=True),
            start=start,
            expiry=expiry
        )
        
        base_url = f"https://{account_name}.blob.core.windows.net/{container_name}"
        return f"{base_url}?{sas_token}"

# -----------------------------
# UI êµ¬ì„±
# -----------------------------


# ì§€ì› ì–¸ì–´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (API)
@st.cache_data
def get_supported_languages():
    try:
        url = "https://api.cognitive.microsofttranslator.com/languages?api-version=3.0&scope=translation"
        # Accept-Language í—¤ë”ë¥¼ 'ko'ë¡œ ì„¤ì •í•˜ì—¬ ì–¸ì–´ ì´ë¦„ì„ í•œêµ­ì–´ë¡œ ë°›ìŒ
        headers = {"Accept-Language": "ko"}
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        data = response.json()
        
        languages = {}
        for code, info in data['translation'].items():
            # "í•œêµ­ì–´ ì´ë¦„ (ì›ì–´ ì´ë¦„)" í˜•ì‹ìœ¼ë¡œ í‘œì‹œ (ì˜ˆ: ì˜ì–´ (English))
            label = f"{info['name']} ({info['nativeName']})"
            languages[label] = code
        return languages
    except Exception as e:
        st.error(f"ì–¸ì–´ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì–¸ì–´ ì œê³µ
        return {"í•œêµ­ì–´ (Korean)": "ko", "ì˜ì–´ (English)": "en"}

LANGUAGES = get_supported_languages()

# ì–¸ì–´ ì½”ë“œë³„ íŒŒì¼ ì ‘ë¯¸ì‚¬ ë§¤í•‘ (ê¸°ë³¸ì ìœ¼ë¡œ ëŒ€ë¬¸ì ì½”ë“œë¥¼ ì‚¬ìš©í•˜ë˜, ì¼ë¶€ ì»¤ìŠ¤í…€ ê°€ëŠ¥)
# ì—¬ê¸°ì„œëŠ” ìë™ ìƒì„± ë¡œì§ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ë³„ë„ ë”•ì…”ë„ˆë¦¬ ë¶ˆí•„ìš”, 
# ë‹¤ë§Œ ì¤‘êµ­ì–´ ë“± íŠ¹ìˆ˜ ì¼€ì´ìŠ¤ë¥¼ ìœ„í•´ ë‚¨ê²¨ë‘˜ ìˆ˜ ìˆìŒ.
LANG_SUFFIX_OVERRIDE = {
    "zh-Hans": "CN",
    "zh-Hant": "TW",
}

# Initialize session state for page navigation
if "page" not in st.session_state:
    st.session_state.page = "í™ˆ"

def change_page(page_name):
    st.session_state.page = page_name

# Initialize AuthManager
auth_manager = AuthManager(STORAGE_CONN_STR)

# Initialize login state
if 'is_logged_in' not in st.session_state:
    st.session_state.is_logged_in = False

# Define role-based menu permissions (Fallback / Admin)
ALL_MENUS = ["í™ˆ", "ë²ˆì—­í•˜ê¸°", "íŒŒì¼ ë³´ê´€í•¨", "ê²€ìƒ‰ & AI ì±„íŒ…", "ë„ë©´/ìŠ¤í™ ë¶„ì„", "ì—‘ì…€ë°ì´í„° ìë™ì¶”ì¶œ", "ì‚¬ì§„ëŒ€ì§€ ìë™ì‘ì„±", "ì‘ì—…ê³„íš ë° íˆ¬ì…ë¹„ ìë™ì‘ì„±", "ê´€ë¦¬ì ì„¤ì •", "ì‚¬ìš©ì ì„¤ì •"]
GUEST_MENUS = ["í™ˆ", "ì‚¬ìš©ì ì„¤ì •"]

# Check if user is logged in
if not st.session_state.is_logged_in:
    render_login_page(auth_manager)
    st.stop()

# User is logged in - get their info
user_info = st.session_state.get('user_info', {})
user_role = user_info.get('role', 'guest')
user_perms = user_info.get('permissions', [])

def get_user_folder_name(user_info):
    """Get sanitized user folder name"""
    if not user_info:
        return "guest"
    # Use name but fallback to ID if empty
    name = user_info.get('name', user_info.get('id', 'guest'))
    return name.strip()

user_folder = get_user_folder_name(user_info)

if user_role == 'admin':
    available_menus = ALL_MENUS
else:
    # Use assigned permissions, ensuring mandatory menus are present
    available_menus = user_perms if user_perms else GUEST_MENUS
    # Ensure "í™ˆ" and "ì‚¬ìš©ì ì„¤ì •" are always available
    if "í™ˆ" not in available_menus:
        available_menus.insert(0, "í™ˆ")
    if "ì‚¬ìš©ì ì„¤ì •" not in available_menus:
        available_menus.append("ì‚¬ìš©ì ì„¤ì •")
    
    # Remove "ê´€ë¦¬ì ì„¤ì •" if somehow present for non-admins
    if "ê´€ë¦¬ì ì„¤ì •" in available_menus:
        available_menus.remove("ê´€ë¦¬ì ì„¤ì •")

with st.sidebar:
    # User profile
    st.markdown(f"### ğŸ‘¤ {user_info.get('name', 'User')}")
    st.caption(f"**{user_info.get('email', '')}**")
    st.caption(f"ê¶Œí•œ: {user_role.upper()}")
    
    if st.button("ğŸšª ë¡œê·¸ì•„ì›ƒ", key="logout_btn", use_container_width=True):
        st.session_state.is_logged_in = False
        st.session_state.user_info = None
        st.rerun()
    
    st.divider()
    
    st.header("ë©”ë‰´")
    # Filter menu based on user role
    menu = st.radio("ì´ë™", available_menus, key="page")
    
    st.divider()
    
    if menu == "ë²ˆì—­í•˜ê¸°":
        st.header("ì„¤ì •")
        # í•œêµ­ì–´ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì°¾ê¸°
        default_index = 0
        lang_labels = list(LANGUAGES.keys())
        for i, label in enumerate(lang_labels):
            if "Korean" in label or "í•œêµ­ì–´" in label:
                default_index = i
                break
                
        target_lang_label = st.selectbox("ëª©í‘œ ì–¸ì–´ ì„ íƒ", lang_labels, index=default_index)
        target_lang_code = LANGUAGES[target_lang_label]
        st.info(f"ì„ íƒëœ ëª©í‘œ ì–¸ì–´: {target_lang_code}")

    # ìê²© ì¦ëª… ìƒíƒœ í™•ì¸
    if STORAGE_CONN_STR and TRANSLATOR_KEY and SEARCH_KEY:
        st.success("âœ… Azure ìê²© ì¦ëª… í™•ì¸ë¨")
    else:
        st.warning("âš ï¸ ì¼ë¶€ Azure ìê²© ì¦ëª…ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")

# Common Header for non-Home pages
if menu != "í™ˆ":
    st.title(menu)


if menu == "í™ˆ":
    # Use the new home_chat module with function calling support
    from home_chat import render_home_chat
    chat_manager = get_chat_manager()
    render_home_chat(chat_manager)
    
if menu == "ë²ˆì—­í•˜ê¸°":
    if "translate_uploader_key" not in st.session_state:
        st.session_state.translate_uploader_key = 0

    uploaded_file = st.file_uploader("ë²ˆì—­í•  ë¬¸ì„œ ì—…ë¡œë“œ (PPTX, PDF, DOCX, XLSX ë“±)", type=["pptx", "pdf", "docx", "xlsx"], key=f"translate_{st.session_state.translate_uploader_key}")

    # ì´ì „ ë²ˆì—­ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    if "last_translation_result" in st.session_state:
        result = st.session_state.last_translation_result
        st.success("âœ… ë²ˆì—­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.markdown(f"[{result['file_name']} ë‹¤ìš´ë¡œë“œ]({result['url']})", unsafe_allow_html=True)
        
        # ê²°ê³¼ë¥¼ ì§€ìš°ê³  ì‹¶ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‹«ê¸° ë²„íŠ¼ ì œê³µ (ì„ íƒ ì‚¬í•­)
        if st.button("ê²°ê³¼ ë‹«ê¸°"):
            del st.session_state.last_translation_result
            st.rerun()

    if st.button("ë²ˆì—­ ì‹œì‘", type="primary", disabled=not uploaded_file):
        if not uploaded_file:
            st.error("íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("Azure Blobì— íŒŒì¼ ì—…ë¡œë“œ ì¤‘..."):
                try:
                    blob_service_client = get_blob_service_client()
                    container_client = blob_service_client.get_container_client(CONTAINER_NAME)
                    
                    # ì»¨í…Œì´ë„ˆ ì ‘ê·¼ ê¶Œí•œ í™•ì¸
                    try:
                        if not container_client.exists():
                            container_client.create_container()
                    except Exception as e:
                        if "AuthenticationFailed" in str(e):
                            st.error("ğŸš¨ ì¸ì¦ ì‹¤íŒ¨: Azure Storage Keyê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. Secrets ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            st.stop()
                        else:
                            raise e

                    # íŒŒì¼ëª… ìœ ë‹ˆí¬í•˜ê²Œ ì²˜ë¦¬ (UUID ì œê±°, ë®ì–´ì“°ê¸° í—ˆìš©)
                    # file_uuid = str(uuid.uuid4())[:8] 
                    original_filename = uploaded_file.name
                    input_blob_name = f"{user_folder}/documents/{original_filename}"
                    
                    # ì—…ë¡œë“œ
                    blob_client = container_client.get_blob_client(input_blob_name)
                    blob_client.upload_blob(uploaded_file, overwrite=True)
                    
                    st.success("ì—…ë¡œë“œ ì™„ë£Œ! ë²ˆì—­ ìš”ì²­ ì¤‘...")
                    
                    # SAS ìƒì„±
                    source_url = generate_sas_url(blob_service_client, CONTAINER_NAME, input_blob_name)
                    
                    # Target URL ì„¤ì •
                    target_base_url = f"https://{blob_service_client.account_name}.blob.core.windows.net/{CONTAINER_NAME}"
                    # Target URLì€ ì»¨í…Œì´ë„ˆ ë˜ëŠ” í´ë” ê²½ë¡œì—¬ì•¼ í•¨ (íŒŒì¼ ê²½ë¡œ ë¶ˆê°€)
                    # ì‚¬ìš©ìë³„ translated í´ë”ë¡œ ì„¤ì •
                    # URL ì¸ì½”ë”© í•„ìš”
                    encoded_user_folder = urllib.parse.quote(user_folder)
                    target_output_url = f"{target_base_url}/{encoded_user_folder}/translated/?{generate_sas_url(blob_service_client, CONTAINER_NAME).split('?')[1]}"
                    
                except Exception as e:
                    st.error(f"ì—…ë¡œë“œ/SAS ìƒì„± ì‹¤íŒ¨: {e}")
                    st.stop()

            with st.spinner("ë²ˆì—­ ì‘ì—… ìš”ì²­ ë° ëŒ€ê¸° ì¤‘..."):
                try:
                    client = get_translation_client()
                    
                    poller = client.begin_translation(
                        inputs=[
                            DocumentTranslationInput(
                                source_url=source_url,
                                storage_type="File",
                                targets=[
                                    TranslationTarget(
                                        target_url=target_output_url,
                                        language=target_lang_code
                                    )
                                ]
                            )
                        ]
                    )
                    
                    result = poller.result()
                    
                    for doc in result:
                        if doc.status == "Succeeded":
                            st.success(f"ë²ˆì—­ ì™„ë£Œ! (ìƒíƒœ: {doc.status})")
                        else:
                            st.error(f"ë¬¸ì„œ ë²ˆì—­ ì‹¤íŒ¨! (ìƒíƒœ: {doc.status})")
                            if doc.error:
                                st.error(f"ì—ëŸ¬ ì½”ë“œ: {doc.error.code}, ë©”ì‹œì§€: {doc.error.message}")
                    
                    # ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
                    time.sleep(2)
                    # UUID í´ë”ê°€ ì—†ìœ¼ë¯€ë¡œ translated í´ë” ì „ì²´ì—ì„œ í•´ë‹¹ íŒŒì¼ëª… ê²€ìƒ‰
                    output_prefix_search = f"{user_folder}/translated/"
                    output_blobs = list(container_client.list_blobs(name_starts_with=output_prefix_search))
                    
                    # ë°©ê¸ˆ ë²ˆì—­ëœ íŒŒì¼ ì°¾ê¸° (íŒŒì¼ëª… ë§¤ì¹­)
                    # Azure ë²ˆì—­ì€ ì›ë³¸ íŒŒì¼ëª…ì„ ìœ ì§€í•˜ê±°ë‚˜ ì–¸ì–´ ì½”ë“œë¥¼ ë¶™ì„
                    target_blobs = []
                    for blob in output_blobs:
                        if original_filename in blob.name:
                            target_blobs.append(blob)
                    
                    if not target_blobs:
                        st.warning(f"ê²°ê³¼ íŒŒì¼ì„ ì°¾ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ê²½ë¡œ: {output_prefix_search})")
                        # Fallback: list all to debug
                        # all_output = list(container_client.list_blobs(name_starts_with=output_prefix_search))
                        # debug_msg = "\n".join([b.name for b in all_output[:10]])
                        # st.error(f"ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\ní˜„ì¬ í´ë” íŒŒì¼ ëª©ë¡:\n{debug_msg}")
                    else:
                        st.subheader("ë‹¤ìš´ë¡œë“œ")
                        for blob in target_blobs:
                            blob_name = blob.name
                            file_name = blob_name.split("/")[-1]
                            
                            # íŒŒì¼ëª…ì— ì–¸ì–´ ì ‘ë¯¸ì‚¬ ì¶”ê°€ (Rename)
                            suffix = LANG_SUFFIX_OVERRIDE.get(target_lang_code, target_lang_code.upper())
                            name_part, ext_part = os.path.splitext(file_name)
                            
                            # ì´ë¯¸ ì ‘ë¯¸ì‚¬ê°€ ìˆëŠ”ì§€ í™•ì¸ (í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ë°©ì§€)
                            if not name_part.endswith(f"_{suffix}"):
                                new_file_name = f"{name_part}_{suffix}{ext_part}"
                                new_blob_name = f"{user_folder}/translated/{new_file_name}"
                                
                                try:
                                    # Rename: Copy to new name -> Delete old
                                    source_blob = container_client.get_blob_client(blob_name)
                                    dest_blob = container_client.get_blob_client(new_blob_name)
                                    
                                    source_sas = generate_sas_url(blob_service_client, CONTAINER_NAME, blob_name)
                                    dest_blob.start_copy_from_url(source_sas)
                                    
                                    # Wait for copy
                                    for _ in range(10):
                                        props = dest_blob.get_blob_properties()
                                        if props.copy.status == "success":
                                            break
                                        time.sleep(0.2)
                                        
                                    source_blob.delete_blob()
                                    
                                    # Update variables for download link
                                    blob_name = new_blob_name
                                    file_name = new_file_name
                                    st.toast(f"íŒŒì¼ëª… ë³€ê²½ë¨: {file_name}")
                                    
                                except Exception as e:
                                    st.warning(f"íŒŒì¼ëª… ë³€ê²½ ì‹¤íŒ¨ (ê¸°ë³¸ ì´ë¦„ìœ¼ë¡œ ìœ ì§€): {e}")

                            # PPTX í°íŠ¸ ë³€ê²½ (Times New Roman)
                            if file_name.lower().endswith(".pptx"):
                                try:
                                    from pptx import Presentation
                                    
                                    # ì„ì‹œ íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
                                    temp_pptx = f"temp_{original_filename}"
                                    blob_client_temp = container_client.get_blob_client(blob_name)
                                    with open(temp_pptx, "wb") as f:
                                        data = blob_client_temp.download_blob().readall()
                                        f.write(data)
                                    
                                    # í°íŠ¸ ë³€ê²½ ë¡œì§
                                    prs = Presentation(temp_pptx)
                                    font_name = "Times New Roman"
                                    
                                    def change_font(shapes):
                                        for shape in shapes:
                                            if shape.has_text_frame:
                                                for paragraph in shape.text_frame.paragraphs:
                                                    for run in paragraph.runs:
                                                        run.font.name = font_name
                                            
                                            if shape.has_table:
                                                for row in shape.table.rows:
                                                    for cell in row.cells:
                                                        if cell.text_frame:
                                                            for paragraph in cell.text_frame.paragraphs:
                                                                for run in paragraph.runs:
                                                                    run.font.name = font_name
                                            
                                            if shape.shape_type == 6: # Group
                                                change_font(shape.shapes)

                                    for slide in prs.slides:
                                        change_font(slide.shapes)
                                    
                                    prs.save(temp_pptx)
                                    
                                    # ë‹¤ì‹œ ì—…ë¡œë“œ (ë®ì–´ì“°ê¸°)
                                    with open(temp_pptx, "rb") as f:
                                        blob_client_temp.upload_blob(f, overwrite=True)
                                    
                                    os.remove(temp_pptx)
                                    st.toast("PPTX í°íŠ¸ ë³€ê²½ ì™„ë£Œ (Times New Roman)")
                                    
                                except Exception as e:
                                    st.warning(f"PPTX í°íŠ¸ ë³€ê²½ ì‹¤íŒ¨: {e}")

                            download_sas = generate_sas_url(blob_service_client, CONTAINER_NAME, blob_name)
                            st.markdown(f"[{file_name} ë‹¤ìš´ë¡œë“œ]({download_sas})", unsafe_allow_html=True)
                            
                            # ê²°ê³¼ ì„¸ì…˜ì— ì €ì¥
                            st.session_state.last_translation_result = {
                                "file_name": file_name,
                                "url": download_sas
                            }
                            
                    # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´ ì—…ë¡œë” ì´ˆê¸°í™” (í‚¤ ë³€ê²½)
                    st.session_state.translate_uploader_key += 1
                    time.sleep(1) # ì ì‹œ ëŒ€ê¸°
                    st.rerun()
                            
                except Exception as e:
                    st.error(f"ë²ˆì—­ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

elif menu == "íŒŒì¼ ë³´ê´€í•¨":
    # st.subheader("ğŸ“‚ í´ë¼ìš°ë“œ íŒŒì¼ ë³´ê´€í•¨") - Removed to avoid duplication
    
    # -----------------------------
    # 1. íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ (Save)
    # -----------------------------
    with st.expander("ğŸ“¤ íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ (ë²ˆì—­ ì—†ì´ ì €ì¥)", expanded=False):
        upload_archive = st.file_uploader("ë³´ê´€í•¨ì— ì €ì¥í•  íŒŒì¼ ì„ íƒ", key="archive_upload")
        if st.button("ì €ì¥í•˜ê¸°", disabled=not upload_archive):
            try:
                blob_service_client = get_blob_service_client()
                container_client = blob_service_client.get_container_client(CONTAINER_NAME)
                
                # file_uuid = str(uuid.uuid4())[:8]
                # Upload to {user_folder}/documents/ (Flat structure)
                blob_name = f"{user_folder}/documents/{upload_archive.name}"
                blob_client = container_client.get_blob_client(blob_name)
                blob_client.upload_blob(upload_archive, overwrite=True)
                st.success(f"'{upload_archive.name}' ì—…ë¡œë“œ ì™„ë£Œ!")
                time.sleep(1)
                st.rerun()
            except Exception as e:
                st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

    st.divider()
    
    if st.button("ğŸ”„ ëª©ë¡ ìƒˆë¡œê³ ì¹¨"):
        st.rerun()
        
    try:
        blob_service_client = get_blob_service_client()
        container_client = blob_service_client.get_container_client(CONTAINER_NAME)
        
        # íƒ­ìœ¼ë¡œ Input/Output êµ¬ë¶„
        tab1, tab2 = st.tabs(["ì›ë³¸ ë¬¸ì„œ (Input)", "ë²ˆì—­ëœ ë¬¸ì„œ (Output)"])
        
        def render_file_list(prefix, tab_name):
            blobs = list(container_client.list_blobs(name_starts_with=prefix))
            blobs.sort(key=lambda x: x.creation_time, reverse=True)
            
            if not blobs:
                st.info(f"{tab_name}ì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            for i, blob in enumerate(blobs):
                file_name = blob.name.split("/")[-1]
                creation_time = blob.creation_time.strftime('%Y-%m-%d %H:%M')
                
                with st.container():
                    col1, col2, col3 = st.columns([6, 2, 2])
                    
                    with col1:
                        sas_url = generate_sas_url(blob_service_client, CONTAINER_NAME, blob.name)
                        st.markdown(f"**[{file_name}]({sas_url})**")
                        st.caption(f"ğŸ“… {creation_time} | ğŸ“¦ {blob.size / 1024:.1f} KB")
                    
                    with col2:
                        # ìˆ˜ì • (ì´ë¦„ ë³€ê²½)
                        with st.popover("ìˆ˜ì •"):
                            new_name = st.text_input("ìƒˆ íŒŒì¼ëª…", value=file_name, key=f"rename_{prefix}_{i}")
                            if st.button("ì´ë¦„ ë³€ê²½", key=f"btn_rename_{prefix}_{i}"):
                                try:
                                    # ìƒˆ ê²½ë¡œ ìƒì„± (ê¸°ì¡´ í´ë” êµ¬ì¡° ìœ ì§€)
                                    path_parts = blob.name.split("/")
                                    folder = "/".join(path_parts[:-1])
                                    new_blob_name = f"{folder}/{new_name}"
                                    
                                    # ë³µì‚¬ (Renameì€ Copy + Delete)
                                    source_blob = container_client.get_blob_client(blob.name)
                                    dest_blob = container_client.get_blob_client(new_blob_name)
                                    
                                    # SAS URL for Copy Source
                                    source_sas = generate_sas_url(blob_service_client, CONTAINER_NAME, blob.name)
                                    
                                    dest_blob.start_copy_from_url(source_sas)
                                    
                                    # ë³µì‚¬ ì™„ë£Œ ëŒ€ê¸° (ê°„ë‹¨í•œ í´ë§)
                                    for _ in range(10):
                                        props = dest_blob.get_blob_properties()
                                        if props.copy.status == "success":
                                            break
                                        time.sleep(0.5)
                                    
                                    # ì›ë³¸ ì‚­ì œ
                                    source_blob.delete_blob()
                                    st.success("ì´ë¦„ ë³€ê²½ ì™„ë£Œ!")
                                    time.sleep(1)
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"ì´ë¦„ ë³€ê²½ ì‹¤íŒ¨: {e}")

                    with col3:
                        # ì‚­ì œ
                        if st.button("ì‚­ì œ", key=f"del_{prefix}_{i}", type="secondary"):
                            try:
                                container_client.delete_blob(blob.name)
                                st.success("ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
                                time.sleep(1)
                                st.rerun()
                            except Exception as e:
                                st.error(f"ì‚­ì œ ì‹¤íŒ¨: {e}")
                    
                    st.divider()

        with tab1:
            render_file_list(f"{user_folder}/documents/", "ë‚´ ë¬¸ì„œ (Documents)")
            
        with tab2:
            render_file_list(f"{user_folder}/translated/", "ë²ˆì—­ëœ ë¬¸ì„œ")
                
    except Exception as e:
        st.error(f"íŒŒì¼ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

elif menu == "ê²€ìƒ‰ & AI ì±„íŒ…":
    # Tabs for Search and Chat to preserve state
    tab1, tab2 = st.tabs(["ğŸ” ë¬¸ì„œ ê²€ìƒ‰", "ğŸ¤– AI ì±„íŒ…"])
    
    with tab1:

        st.subheader("ğŸ” PDF ë¬¸ì„œ ê²€ìƒ‰")
        
        # File Uploader for Document Search
        with st.expander("ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ (ë‚´ ë¬¸ì„œ)", expanded=False):
            doc_upload = st.file_uploader("ê²€ìƒ‰í•  ë¬¸ì„œ ì—…ë¡œë“œ", type=['pdf', 'docx', 'txt', 'pptx'], key="doc_search_upload")
            if doc_upload and st.button("ì—…ë¡œë“œ", key="btn_doc_upload"):
                try:
                    blob_service_client = get_blob_service_client()
                    container_client = blob_service_client.get_container_client(CONTAINER_NAME)
                    
                    # file_uuid = str(uuid.uuid4())[:8]
                    # Upload to {user_folder}/documents/ (Flat structure)
                    blob_name = f"{user_folder}/documents/{doc_upload.name}"
                    blob_client = container_client.get_blob_client(blob_name)
                    blob_client.upload_blob(doc_upload, overwrite=True)
                    st.success(f"'{doc_upload.name}' ì—…ë¡œë“œ ì™„ë£Œ! (ì¸ë±ì‹±ì— ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
                except Exception as e:
                    st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # Search Input
        query = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", placeholder="ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”...")
        
        # Search Options (Expander)
        with st.expander("âš™ï¸ ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •", expanded=False):
            c1, c2 = st.columns(2)
            with c1:
                use_semantic = st.checkbox("ì‹œë§¨í‹± ë­ì»¤", value=False, help="ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (Standard Tier ì´ìƒ)")
            with c2:
                search_mode_opt = st.radio("ê²€ìƒ‰ ëª¨ë“œ", ["all (AND)", "any (OR)"], index=0, horizontal=True, help="all: ëª¨ë“  ë‹¨ì–´ í¬í•¨, any: í•˜ë‚˜ë¼ë„ í¬í•¨")
                search_mode = "all" if "all" in search_mode_opt else "any"
        
        
        if query:
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                search_manager = get_search_manager()
                
                # Filter by user folder
                # Construct prefix URL: https://{account}.blob.core.windows.net/{container}/{user_folder}/
                account_name = get_blob_service_client().account_name
                # Need to handle spaces in user_folder for URL
                encoded_user_folder = urllib.parse.quote(user_folder)
                prefix_url = f"https://{account_name}.blob.core.windows.net/{CONTAINER_NAME}/{encoded_user_folder}/"
                
                # OData filter: startswith(metadata_storage_path, 'prefix_url')
                # Also allow 'all' access for admin if needed, but user requested isolation.
                # Assuming strict isolation.
                filter_expr = f"search.ismatch('{encoded_user_folder}/*', 'metadata_storage_path') or startswith(metadata_storage_path, '{prefix_url}')"
                # Note: search.ismatch might not work on SimpleField. startswith is safer for path.
                filter_expr = f"startswith(metadata_storage_path, '{prefix_url}')"
                
                results = search_manager.search(query, filter_expr=filter_expr, use_semantic_ranker=use_semantic, search_mode=search_mode)
                
                if not results:
                    st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.success(f"ì´ {len(results)}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    for result in results:
                        with st.container():
                            file_name = result.get('metadata_storage_name', 'Unknown File')
                            path = result.get('metadata_storage_path', '')
                            
                            # í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬
                            highlights = result.get('@search.highlights')
                            if highlights:
                                # content ë˜ëŠ” content_exactì—ì„œ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ
                                # ì—¬ëŸ¬ ê°œì˜ í•˜ì´ë¼ì´íŠ¸ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•©ì³ì„œ ë³´ì—¬ì¤Œ
                                snippets = []
                                if 'content' in highlights:
                                    snippets.extend(highlights['content'])
                                if 'content_exact' in highlights:
                                    snippets.extend(highlights['content_exact'])
                                
                                # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
                                unique_snippets = list(set(snippets))[:3]
                                content_snippet = " ... ".join(unique_snippets)
                            else:
                                # í•˜ì´ë¼ì´íŠ¸ ì—†ìœ¼ë©´ ê¸°ë³¸ ìŠ¤ë‹ˆí«
                                content_snippet = result.get('content', '')[:300] + "..."
                            
                            blob_path = ""
                            try:
                                if CONTAINER_NAME in path:
                                    blob_path = path.split(f"/{CONTAINER_NAME}/")[-1]
                                    blob_path = urllib.parse.unquote(blob_path)
                            except:
                                pass
                                
                            st.markdown(f"### ğŸ“„ {file_name}")
                            st.markdown(f"> {content_snippet}", unsafe_allow_html=True) # HTML íƒœê·¸(bold) í—ˆìš©
                            
                            if blob_path:
                                try:
                                    blob_service_client = get_blob_service_client()
                                    
                                    # Content-Type ê²°ì • (í™•ì¥ì ìš°ì„  ì ìš©)
                                    # ë©”íƒ€ë°ì´í„°ê°€ application/octet-streamì¸ ê²½ìš°ê°€ ë§ì•„ í™•ì¥ìë¡œ ê°•ì œ ì„¤ì •
                                    if file_name.lower().endswith('.pdf'):
                                        content_type = "application/pdf"
                                    else:
                                        content_type = result.get('metadata_storage_content_type')
                                        if not content_type or content_type == "application/octet-stream":
                                            import mimetypes
                                            content_type, _ = mimetypes.guess_type(file_name)
                                    
                                    # Blob SAS ìƒì„± (Content-Disposition: inline ì„¤ì • + Content-Type ê°•ì œ)
                                    sas_token = generate_blob_sas(
                                        account_name=blob_service_client.account_name,
                                        container_name=CONTAINER_NAME,
                                        blob_name=blob_path,
                                        account_key=blob_service_client.credential.account_key,
                                        permission=BlobSasPermissions(read=True),
                                        expiry=datetime.utcnow() + timedelta(hours=1),
                                        content_disposition="inline", # ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸° ê°•ì œ
                                        content_type=content_type # ì˜¬ë°”ë¥¸ MIME íƒ€ì… ì„¤ì •
                                    )
                                    
                                    sas_url = f"https://{blob_service_client.account_name}.blob.core.windows.net/{CONTAINER_NAME}/{urllib.parse.quote(blob_path)}?{sas_token}"
                                    
                                    # ìƒˆ íƒ­ì—ì„œ ì—´ê¸° (target="_blank")
                                    st.markdown(f'<a href="{sas_url}" target="_blank">ğŸ“„ ë¬¸ì„œ ì—´ê¸° (ìƒˆ íƒ­)</a>', unsafe_allow_html=True)
                                except Exception as e:
                                    st.caption(f"ë¬¸ì„œ ë§í¬ ìƒì„± ì‹¤íŒ¨: {e}")
                            
                            st.divider()
    
    with tab2:
        st.subheader("ğŸ¤– AI ë¬¸ì„œ ë„ìš°ë¯¸ (GPT-5.2)")
        st.caption("Azure OpenAI(GPT-5.2)ì™€ ë¬¸ì„œ ê²€ìƒ‰ì„ í™œìš©í•œ ì •í™•í•œ ë‹µë³€ ì œê³µ")
        
        # Initialize chat history in session state
        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []
        
        # Display chat messages
        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                
                # Display citations if present
                if "citations" in message and message["citations"]:
                    st.markdown("---")
                    st.caption("ğŸ“š **ì°¸ì¡° ë¬¸ì„œ:**")
                    for i, citation in enumerate(message["citations"], 1):
                        filepath = citation.get('filepath', 'Unknown')
                        url = citation.get('url', '')
                        
                        # Generate SAS URL if we have blob path
                        if url:
                            display_url = url
                        else:
                            # Try to generate SAS URL from filepath
                            try:
                                blob_service_client = get_blob_service_client()
                                display_url = generate_sas_url(blob_service_client, CONTAINER_NAME, filepath)
                            except:
                                display_url = "#"
                        
                        st.markdown(f"{i}. [{filepath}]({display_url})")
        
        # -----------------------------
        # ê²€ìƒ‰ ì˜µì…˜ (Chat Tab) - Bottom of chat area
        # -----------------------------
        st.write("")
        with st.expander("âš™ï¸ ê³ ê¸‰ ê²€ìƒ‰ ì˜µì…˜ (RAG ì„¤ì •)", expanded=False):
            c1, c2 = st.columns(2)
            with c1:
                chat_use_semantic = st.checkbox("ì‹œë§¨í‹± ë­ì»¤ ì‚¬ìš©", value=False, key="chat_use_semantic", help="ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ë¥¼ ë†’ì…ë‹ˆë‹¤.")
            with c2:
                chat_search_mode_opt = st.radio("ê²€ìƒ‰ ëª¨ë“œ", ["all (AND)", "any (OR)"], index=1, horizontal=True, key="chat_search_mode", help="any: í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê²€ìƒ‰ (ì¶”ì²œ)")
                chat_search_mode = "all" if "all" in chat_search_mode_opt else "any"

        # Chat input
        if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 10-P-101Aì˜ ì‚¬ì–‘ì€ ë¬´ì—‡ì¸ê°€ìš”?)"):
            # Add user message to chat history
            st.session_state.chat_messages.append({"role": "user", "content": prompt})
            
            # Display user message
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Get AI response
            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        chat_manager = get_chat_manager()
                        
                        # Prepare conversation history (exclude citations from history)
                        conversation_history = [
                            {"role": msg["role"], "content": msg["content"]}
                            for msg in st.session_state.chat_messages[:-1]  # Exclude the just-added user message
                        ]
                        
                        # Pass the selected search options to the chat manager
                        response_text, citations, context = chat_manager.get_chat_response(
                            prompt, 
                            conversation_history, 
                            search_mode=chat_search_mode, 
                            use_semantic_ranker=chat_use_semantic
                        )
                        
                        # Display response
                        st.markdown(response_text)
                        
                        # Display citations
                        if citations:
                            st.markdown("---")
                            st.caption("ğŸ“š **ì°¸ì¡° ë¬¸ì„œ:**")
                            for i, citation in enumerate(citations, 1):
                                filepath = citation.get('filepath', 'Unknown')
                                url = citation.get('url', '')
                                
                                # Generate SAS URL if we have blob path
                                if url:
                                    display_url = url
                                else:
                                    # Try to generate SAS URL from filepath
                                    blob_service_client = get_blob_service_client()
                                    display_url = generate_sas_url(blob_service_client, CONTAINER_NAME, filepath)
                                
                                st.markdown(f"{i}. [{filepath}]({display_url})")
                        
                        # Add assistant response to chat history
                        st.session_state.chat_messages.append({
                            "role": "assistant",
                            "content": response_text,
                            "citations": citations
                        })
                        
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # Clear chat button
        # Clear chat button
        if st.session_state.chat_messages:
            if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
                st.session_state.chat_messages = []
                st.rerun()

elif menu == "ë„ë©´/ìŠ¤í™ ë¶„ì„":
    # st.subheader("ğŸ—ï¸ ë„ë©´/ìŠ¤í™ ì •ë°€ ë¶„ì„ (RAG)") - Removed to avoid duplication
    st.caption("Azure Document Intelligenceë¥¼ í™œìš©í•œ ê³ ì •ë°€ ë¬¸ì„œ ë¶„ì„ ë° ì§ˆì˜ì‘ë‹µ")
    
    with st.expander("â„¹ï¸ Document Intelligenceê°€ ì™œ ë” ì¢‹ì€ê°€ìš”?", expanded=False):
        st.markdown("""
        **ê±´ì„¤ EPC ì„¤ê³„ ë‹´ë‹¹ìë‹˜ê»˜ ì´ ì„œë¹„ìŠ¤ê°€ í•„ìš”í•œ ì´ìœ ëŠ” í¬ê²Œ 3ê°€ì§€ì…ë‹ˆë‹¤.**

        1. **í‘œ(Table) ì¶”ì¶œì˜ ì •í™•ë„**: ì¼ë°˜ OCRì€ í‘œ ì•ˆì˜ ë°ì´í„°ë¥¼ ì½ì„ ë•Œ ì¤„ì´ ë°€ë¦¬ê±°ë‚˜ í…ìŠ¤íŠ¸ê°€ ì„ì´ê¸° ì‰½ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ Document IntelligenceëŠ” í–‰ê³¼ ì—´ì˜ êµ¬ì¡°ë¥¼ ì™„ë²½íˆ íŒŒì•…í•˜ì—¬ ì—‘ì…€ì²˜ëŸ¼ ì •êµí•˜ê²Œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        2. **ë ˆì´ì•„ì›ƒ ë¶„ì„**: ì œëª©, ë³¸ë¬¸, ê°ì£¼, í˜ì´ì§€ ë²ˆí˜¸ ë“±ì„ êµ¬ë¶„í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ìš°ì„ ìˆœìœ„ë¥¼ ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        3. **ì²´í¬ë°•ìŠ¤ ë° ì„œëª… ì¸ì‹**: ì„¤ê³„ ê²€í† ì„œë‚˜ ìŠ¹ì¸ ë¬¸ì„œì— í¬í•¨ëœ ì²´í¬ í‘œì‹œë‚˜ ì„œëª… ì—¬ë¶€ê¹Œì§€ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)

    tab1, tab2 = st.tabs(["ğŸ“¤ ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¶„ì„", "ğŸ’¬ ë¶„ì„ ë¬¸ì„œ ì±„íŒ…"])
    
    with tab1:
        st.markdown(f"### 1. ë¶„ì„í•  ë¬¸ì„œ ì—…ë¡œë“œ ({user_folder}/drawings í´ë”)")
        
        if "drawing_uploader_key" not in st.session_state:
            st.session_state.drawing_uploader_key = 0
            
        uploaded_files = st.file_uploader("PDF ë„ë©´, ìŠ¤í™, ì‚¬ì–‘ì„œ ë“±ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True, type=['pdf', 'png', 'jpg', 'jpeg', 'tiff', 'bmp'], key=f"drawing_{st.session_state.drawing_uploader_key}")
        
        if uploaded_files:
            if st.button("ì—…ë¡œë“œ ë° ë¶„ì„ ì‹œì‘"):
                blob_service_client = get_blob_service_client()
                container_client = blob_service_client.get_container_client(CONTAINER_NAME)
                doc_intel_manager = get_doc_intel_manager()
                search_manager = get_search_manager()
                
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                total_files = len(uploaded_files)
                
                for idx, file in enumerate(uploaded_files):
                    try:
                        # Normalize filename to NFC (to match search query logic)
                        import unicodedata
                        safe_filename = unicodedata.normalize('NFC', file.name)
                        
                        status_text.text(f"ì²˜ë¦¬ ì¤‘ ({idx+1}/{total_files}): {safe_filename}")
                        
                        blob_path = f"{user_folder}/drawings/{safe_filename}"
                        # 2. Upload to Azure Blob Storage
                        status_text.text(f"ì—…ë¡œë“œ ì¤‘ ({idx+1}/{total_files}): {file.name}...")
                        blob_client = blob_service_client.get_blob_client(container=CONTAINER_NAME, blob=blob_path)
                        
                        # CRITICAL: Reset file pointer to ensure full upload
                        file.seek(0)
                        blob_client.upload_blob(file, overwrite=True)
                        
                        # Verify upload size
                        props = blob_client.get_blob_properties()
                        if props.size != file.size:
                            st.error(f"âš ï¸ íŒŒì¼ ì—…ë¡œë“œ í¬ê¸° ë¶ˆì¼ì¹˜! (ì›ë³¸: {file.size}, ì—…ë¡œë“œë¨: {props.size})")
                        else:
                            print(f"DEBUG: Upload verified. Size: {props.size} bytes")

                        # Generate SAS Token for Document Intelligence access
                        sas_token = generate_blob_sas(
                            account_name=blob_service_client.account_name,
                            container_name=CONTAINER_NAME,
                            blob_name=blob_path,
                            account_key=blob_service_client.credential.account_key,
                            permission=BlobSasPermissions(read=True),
                            expiry=datetime.utcnow() + timedelta(hours=1)
                        )
                        blob_url = f"https://{blob_service_client.account_name}.blob.core.windows.net/{CONTAINER_NAME}/{urllib.parse.quote(blob_path)}?{sas_token}"
                        
                        # 3. Analyze with Document Intelligence
                        status_text.text(f"ë¶„ì„ ì¤‘ ({idx+1}/{total_files}): {file.name} - Document Intelligence Layout ëª¨ë¸ ì‹¤í–‰...")
                        page_chunks = doc_intel_manager.analyze_document(blob_url)
                        
                        # 4. Indexing (Push to Search) - One document per page
                        # 4. Indexing (Push to Search) - One document per page
                        detected_pages = [chunk['page_number'] for chunk in page_chunks]
                        status_text.text(f"ì¸ë±ì‹± ì¤‘ ({idx+1}/{total_files}): {safe_filename} - {len(page_chunks)} í˜ì´ì§€ ë°œê²¬ (Pages: {detected_pages})")
                        
                        if len(page_chunks) == 0:
                            st.warning(f"âš ï¸ ê²½ê³ : '{file.name}'ì—ì„œ í˜ì´ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                        documents_to_index = []
                        for page_chunk in page_chunks:
                            # Create document object for each page
                            # ID must be unique and URL safe. Include page number in ID.
                            import base64
                            page_id_str = f"{blob_path}_page_{page_chunk['page_number']}"
                            doc_id = base64.urlsafe_b64encode(page_id_str.encode('utf-8')).decode('utf-8')
                            
                            document = {
                                "id": doc_id,
                                "content": page_chunk['content'],
                                "content_exact": page_chunk['content'],
                                "metadata_storage_name": f"{safe_filename} (p.{page_chunk['page_number']})",
                                "metadata_storage_path": f"https://{blob_service_client.account_name}.blob.core.windows.net/{CONTAINER_NAME}/{blob_path}#page={page_chunk['page_number']}",
                                "metadata_storage_last_modified": datetime.utcnow().isoformat() + "Z",
                                "metadata_storage_size": file.size,
                                "metadata_storage_content_type": file.type,
                                "project": "drawings_analysis"  # Tag for filtering
                            }
                            documents_to_index.append(document)
                        
                        # Batch upload all pages
                        if documents_to_index:
                            success, msg = search_manager.upload_documents(documents_to_index)
                            if not success:
                                st.error(f"ì¸ë±ì‹± ì‹¤íŒ¨ ({file.name}): {msg}")
                        
                        progress_bar.progress((idx + 1) / total_files)
                        
                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ ({file.name}): {str(e)}")
                
                status_text.text("ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.success("ì—…ë¡œë“œ, ë¶„ì„ ë° ì¸ë±ì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                # ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´ ì—…ë¡œë” ì´ˆê¸°í™”
                st.session_state.drawing_uploader_key += 1
                time.sleep(2)
                st.rerun()

    with tab2:
        st.markdown("### ğŸ’¬ ë„ë©´/ìŠ¤í™ ì „ë¬¸ ì±„íŒ… (GPT-5.2)")
        
        # Display analyzed documents
        st.markdown("#### ğŸ“‹ ë¶„ì„ëœ ë¬¸ì„œ ëª©ë¡")
        try:
            blob_service_client = get_blob_service_client()
            container_client = blob_service_client.get_container_client(CONTAINER_NAME)
            
            # List files in user's drawings folder
            prefix = f"{user_folder}/drawings/"
            blobs = container_client.list_blobs(name_starts_with=prefix)
            blob_list = []
            available_filenames = []
            for blob in blobs:
                if not blob.name.endswith('/'):  # Skip folder markers
                    filename = blob.name.replace(prefix, '')
                    blob_list.append({
                        'name': filename,
                        'size': blob.size,
                        'modified': blob.last_modified
                    })
                    available_filenames.append(filename)
            
            # Sort by modified date (most recent first)
            blob_list.sort(key=lambda x: x['modified'], reverse=True)
            
            selected_filenames = []
            
            if blob_list:
                st.info(f"ì´ {len(blob_list)}ê°œì˜ ë¬¸ì„œê°€ ë¶„ì„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¶„ì„í•  ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”.")
                
                # Add "Select All" checkbox
                def toggle_all():
                    new_state = st.session_state.select_all_files
                    for key in st.session_state.keys():
                        if key.startswith("chk_"):
                            st.session_state[key] = new_state

                select_all = st.checkbox("ì „ì²´ ì„ íƒ", value=True, key="select_all_files", on_change=toggle_all)
                
                # Display as expandable list
                with st.expander("ğŸ“„ ë¬¸ì„œ ëª©ë¡ ë° ì„ íƒ", expanded=True):
                    for idx, blob_info in enumerate(blob_list, 1):
                        col0, col1, col2, col3 = st.columns([0.5, 4, 1.2, 1])
                        with col0:
                            # Checkbox for selection
                            is_selected = st.checkbox(f"select_{idx}", value=select_all, key=f"chk_{blob_info['name']}", label_visibility="collapsed")
                            if is_selected:
                                selected_filenames.append(blob_info['name'])
                        
                        with col1:
                            size_mb = blob_info['size'] / (1024 * 1024)
                            modified_str = blob_info['modified'].strftime('%Y-%m-%d %H:%M')
                            st.markdown(f"**{blob_info['name']}** ({size_mb:.2f} MB)")
                        
                        with col2:
                            # JSON Download Logic
                            json_key = f"json_data_{blob_info['name']}"
                            
                            if json_key not in st.session_state:
                                if st.button("JSON ìƒì„±", key=f"gen_json_{blob_info['name']}"):
                                    with st.spinner("ë°ì´í„° ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                                        search_manager = get_search_manager()
                                        docs = search_manager.get_document_json(blob_info['name'])
                                        if docs:
                                            import json
                                            json_str = json.dumps(docs, ensure_ascii=False, indent=2)
                                            st.session_state[json_key] = json_str
                                            st.rerun()
                                        else:
                                            st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                # Show download button
                                json_data = st.session_state[json_key]
                                st.download_button(
                                    label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                                    data=json_data,
                                    file_name=f"{blob_info['name']}.json",
                                    mime="application/json",
                                    key=f"dl_json_{blob_info['name']}"
                                )

                        with col3:
                            if st.button("ğŸ—‘ï¸ ì‚­ì œ", key=f"del_{blob_info['name']}"):
                                try:
                                    # 1. Delete from Blob Storage
                                    blob_client = container_client.get_blob_client(f"drawings/{blob_info['name']}")
                                    blob_client.delete_blob()
                                    
                                    # 2. Delete from Search Index
                                    search_manager = get_search_manager()
                                    
                                    # Find docs to delete
                                    safe_filename = blob_info['name'].replace("'", "''")
                                    
                                    # Clean up index
                                    results = search_manager.search_client.search(
                                        search_text="*",
                                        filter=f"project eq 'drawings_analysis'",
                                        select=["id", "metadata_storage_name"]
                                    )
                                    
                                    ids_to_delete = []
                                    import unicodedata
                                    safe_blob_name = unicodedata.normalize('NFC', blob_info['name'])
                                    
                                    for doc in results:
                                        if doc['metadata_storage_name'].startswith(safe_blob_name):
                                            ids_to_delete.append({"id": doc['id']})
                                    
                                    if ids_to_delete:
                                        search_manager.search_client.delete_documents(documents=ids_to_delete)
                                    
                                    # Clear JSON state if exists
                                    json_key = f"json_data_{blob_info['name']}"
                                    if json_key in st.session_state:
                                        del st.session_state[json_key]

                                    st.success(f"{blob_info['name']} ì‚­ì œ ì™„ë£Œ")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"ì‚­ì œ ì‹¤íŒ¨: {e}")
            else:
                st.warning("ë¶„ì„ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. 'ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¶„ì„' íƒ­ì—ì„œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        except Exception as e:
            st.error(f"ë¬¸ì„œ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        st.divider()
        
        # Chat Interface (Similar to main chat but focused)
        if "rag_chat_messages" not in st.session_state:
            st.session_state.rag_chat_messages = []
            
        for message in st.session_state.rag_chat_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if "citations" in message and message["citations"]:
                    st.markdown("---")
                    st.caption("ğŸ“š **ì°¸ì¡° ë¬¸ì„œ:**")
                    for i, citation in enumerate(message["citations"], 1):
                        filepath = citation.get('filepath', 'Unknown')
                        url = citation.get('url', '')
                        
                        # Generate SAS URL for browser viewing
                        if url:
                            display_url = url
                        else:
                            try:
                                blob_service_client = get_blob_service_client()
                                # Generate SAS with inline content disposition
                                sas_token = generate_blob_sas(
                                    account_name=blob_service_client.account_name,
                                    container_name=CONTAINER_NAME,
                                    blob_name=filepath,
                                    account_key=blob_service_client.credential.account_key,
                                    permission=BlobSasPermissions(read=True),
                                    expiry=datetime.utcnow() + timedelta(hours=1),
                                    content_disposition="inline",
                                    content_type="application/pdf"
                                )
                                display_url = f"https://{blob_service_client.account_name}.blob.core.windows.net/{CONTAINER_NAME}/{urllib.parse.quote(filepath)}?{sas_token}"
                                
                                # Add page number if available
                                page_num = citation.get('page')
                                if page_num:
                                    display_url += f"#page={page_num}"
                            except:
                                display_url = "#"
                        
                        st.markdown(f"{i}. [{filepath}]({display_url})")

        if prompt := st.chat_input("ë„ë©´ì´ë‚˜ ìŠ¤í™ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
            st.session_state.rag_chat_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            with st.chat_message("assistant"):
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    try:
                        chat_manager = get_chat_manager()
                        
                        conversation_history = [
                            {"role": msg["role"], "content": msg["content"]}
                            for msg in st.session_state.rag_chat_messages[:-1]
                        ]
                        
                        # Use 'any' search mode for better recall (find documents even with partial keyword match)
                        # This is important because technical drawings may have specific terms
                        # Filter to only search documents from the drawings folder
                        # Pass selected_filenames for specific file filtering
                        # If selected_filenames is empty (user deselected all), we should probably warn or search nothing.
                        # But for now let's pass it. If empty, the chat manager might search nothing or all depending on logic.
                        # Actually, let's default to all if none selected? No, user explicitly deselected.
                        # Let's pass the list as is.
                        
                        # Note: selected_filenames comes from the UI loop above
                        current_files = locals().get('selected_filenames', [])
                        
                        response_text, citations, context = chat_manager.get_chat_response(
                            prompt, 
                            conversation_history,
                            search_mode="any",  # Changed from 'all' to 'any' for better recall
                            use_semantic_ranker=False,  # Disable semantic ranker if using Basic tier
                            filter_expr="project eq 'drawings_analysis'",  # Only search drawings documents
                            available_files=current_files
                        )
                        
                        st.markdown(response_text)
                        
                        if citations:
                            st.markdown("---")
                            st.caption("ğŸ“š **ì°¸ì¡° ë¬¸ì„œ:**")
                            for i, citation in enumerate(citations, 1):
                                filepath = citation.get('filepath', 'Unknown')
                                url = citation.get('url', '')
                                
                                # Generate SAS URL for browser viewing
                                if url:
                                    display_url = url
                                else:
                                    try:
                                        blob_service_client = get_blob_service_client()
                                        # Generate SAS with inline content disposition
                                        sas_token = generate_blob_sas(
                                            account_name=blob_service_client.account_name,
                                            container_name=CONTAINER_NAME,
                                            blob_name=filepath,
                                            account_key=blob_service_client.credential.account_key,
                                            permission=BlobSasPermissions(read=True),
                                            expiry=datetime.utcnow() + timedelta(hours=1),
                                            content_disposition="inline",
                                            content_type="application/pdf"
                                        )
                                        display_url = f"https://{blob_service_client.account_name}.blob.core.windows.net/{CONTAINER_NAME}/{urllib.parse.quote(filepath)}?{sas_token}"
                                        
                                        # Add page number if available
                                        page_num = citation.get('page')
                                        if page_num:
                                            display_url += f"#page={page_num}"
                                    except:
                                        display_url = "#"
                                
                                st.markdown(f"{i}. [{filepath}]({display_url})")
                        
                        # Debug: Show Context
                        with st.expander("ğŸ” ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ í™•ì¸ (Debug Context)", expanded=False):
                            st.text_area("LLMì—ê²Œ ì „ë‹¬ëœ ì›ë¬¸ ë°ì´í„°", value=context, height=300)

                        st.session_state.rag_chat_messages.append({
                            "role": "assistant",
                            "content": response_text,
                            "citations": citations,
                            "context": context
                        })
                        st.rerun()


                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜: {e}")
                        import traceback
                        st.code(traceback.format_exc())

    # -----------------------------
    # ë””ë²„ê¹… ë„êµ¬ (Debug Tools)
    # -----------------------------
    with st.expander("ğŸ› ï¸ ì¸ë±ìŠ¤ ë° ê²€ìƒ‰ ì§„ë‹¨ (Debug Tools)", expanded=False):
        st.warning("ì´ ë„êµ¬ëŠ” ê²€ìƒ‰ ë¬¸ì œë¥¼ ì§„ë‹¨í•˜ê¸° ìœ„í•œ ê²ƒì…ë‹ˆë‹¤.")
        
        if st.button("ğŸ” ì¸ë±ìŠ¤ ìƒíƒœ ë° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"):
            try:
                search_manager = get_search_manager()
                client = search_manager.search_client
                
                st.write("### 1. ì¸ë±ìŠ¤ ë¬¸ì„œ í™•ì¸ (project='drawings_analysis')")
                results = client.search(search_text="*", filter="project eq 'drawings_analysis'", select=["id", "metadata_storage_name", "project"], top=20)
                
                docs = list(results)
                st.write(f"ì´ {len(docs)}ê°œì˜ ë¬¸ì„œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                
                if docs:
                    for doc in docs:
                        st.code(f"ID: {doc['id']}\nName: {doc['metadata_storage_name']}\nProject: {doc['project']}")
                else:
                    st.error("ì¸ë±ìŠ¤ì— 'drawings_analysis' í”„ë¡œì íŠ¸ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤!")
                
                st.write("---")
                st.write("### 2. í‚¤ì›Œë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ('foundation loading data')")
                search_results = client.search(search_text="foundation loading data", filter="project eq 'drawings_analysis'", top=5, select=["metadata_storage_name", "content"])
                search_docs = list(search_results)
                
                st.write(f"ê²€ìƒ‰ ê²°ê³¼: {len(search_docs)}ê°œ")
                for doc in search_docs:
                    st.text(f"Match: {doc['metadata_storage_name']}")
                    st.caption(f"Content: {doc['content'][:200]}...")
                
                st.write("---")
                st.write("### 3. ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ('*')")
                wild_results = client.search(search_text="*", filter="project eq 'drawings_analysis'", top=5, select=["metadata_storage_name", "content"])
                wild_docs = list(wild_results)
                
                st.write(f"ê²€ìƒ‰ ê²°ê³¼: {len(wild_docs)}ê°œ")
                for doc in wild_docs:
                    st.text(f"Match: {doc['metadata_storage_name']}")
                    st.caption(f"Content: {doc['content'][:200]}...")
                    
            except Exception as e:
                st.error(f"ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                st.code(str(e))
        
        st.write("---")
        st.write("### ğŸ§ª ì‚¬ìš©ì ì§€ì • ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
        debug_query = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥ (ì˜ˆ: filter element)", key="debug_query")
        if st.button("ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰", key="run_debug_search"):
            if debug_query:
                try:
                    search_manager = get_search_manager()
                    client = search_manager.search_client
                    
                    st.write(f"Query: '{debug_query}'")
                    # Use 'any' search mode to match behavior
                    results = client.search(
                        search_text=debug_query, 
                        filter="project eq 'drawings_analysis'", 
                        search_mode="any",
                        select=["metadata_storage_name", "content"],
                        top=10
                    )
                    docs = list(results)
                    st.write(f"ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ")
                    
                    if docs:
                        for doc in docs:
                            st.text(f"Match: {doc['metadata_storage_name']}")
                            st.caption(f"Content: {doc['content'][:200]}...")
                    else:
                        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

        st.write("---")
        st.write("### âš ï¸ ì¸ë±ìŠ¤ ì´ˆê¸°í™”")
        if st.button("ğŸ—‘ï¸ ëª¨ë“  ë„ë©´ ë°ì´í„° ì‚­ì œ (Index & Blob)", type="primary"):
            try:
                # 1. Delete all blobs in drawings/
                blob_service_client = get_blob_service_client()
                container_client = blob_service_client.get_container_client(CONTAINER_NAME)
                blobs = container_client.list_blobs(name_starts_with="drawings/")
                for blob in blobs:
                    container_client.delete_blob(blob.name)
                
                # 2. Delete all docs in index with project='drawings_analysis'
                search_manager = get_search_manager()
                results = search_manager.search_client.search(
                    search_text="*",
                    filter="project eq 'drawings_analysis'",
                    select=["id"]
                )
                ids_to_delete = [{"id": doc['id']} for doc in results]
                if ids_to_delete:
                    # Delete in batches of 1000 if needed, but for now simple
                    search_manager.search_client.delete_documents(documents=ids_to_delete)
                
                st.success("ëª¨ë“  ë„ë©´ ë°ì´í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                st.rerun()
            except Exception as e:
                st.error(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

        if st.button("ğŸ§¹ 'í˜ì´ì§€ ë²ˆí˜¸ ì—†ëŠ”' ì¤‘ë³µ ë°ì´í„° ì •ë¦¬ (ê¶Œì¥)", help="ì¸ë±ìŠ¤ì—ì„œ (p.N) í˜•ì‹ì´ ì•„ë‹Œ ì˜ëª»ëœ ë°ì´í„°ë¥¼ ì°¾ì•„ ì‚­ì œí•©ë‹ˆë‹¤."):
            try:
                search_manager = get_search_manager()
                results = search_manager.search_client.search(
                    search_text="*",
                    filter="project eq 'drawings_analysis'",
                    select=["id", "metadata_storage_name"],
                    top=1000
                )
                
                ids_to_delete = []
                count = 0
                for doc in results:
                    name = doc['metadata_storage_name']
                    # Delete if it doesn't contain "(p." (standard page suffix)
                    if "(p." not in name:
                        ids_to_delete.append({"id": doc['id']})
                        count += 1
                
                if ids_to_delete:
                    search_manager.search_client.delete_documents(documents=ids_to_delete)
                    st.success(f"ì •ë¦¬ ì™„ë£Œ! {count}ê°œì˜ ì¤‘ë³µ/ì˜ëª»ëœ ë¬¸ì„œë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
                    st.rerun()
                else:
                    st.info("ì‚­ì œí•  ì˜ëª»ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ê°€ ê¹¨ë—í•©ë‹ˆë‹¤! âœ¨")
                    
            except Exception as e:
                st.error(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        with st.expander("ğŸ“Š ì„ íƒëœ íŒŒì¼ í† í° ë¶„ì„ (Token Analyzer)", expanded=False):
            st.caption("íŠ¹ì • íŒŒì¼ì˜ ì¸ë±ìŠ¤ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ í† í° ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•©ë‹ˆë‹¤.")
            target_file_input = st.text_input("ë¶„ì„í•  íŒŒì¼ëª… (ì¼ë¶€ë§Œ ì…ë ¥í•´ë„ ë¨)", value="PH20-810-EC115-00540")
            
            if st.button("ë¶„ì„ ì‹¤í–‰", key="analyze_token_btn"):
                try:
                    search_manager = get_search_manager()
                    # Search for chunks matching the filename
                    results = search_manager.search_client.search(
                        search_text="*",
                        filter=f"search.ismatch('{target_file_input}', 'metadata_storage_name')",
                        select=["metadata_storage_name", "content", "metadata_storage_path"]
                    )
                    
                    results_list = list(results)
                    st.info(f"ê²€ìƒ‰ëœ ì²­í¬(Chunk) ìˆ˜: {len(results_list)}ê°œ")
                    
                    total_chars = 0
                    for i, doc in enumerate(results_list):
                        content = doc.get('content', '')
                        char_count = len(content)
                        total_chars += char_count
                        
                        with st.expander(f"Chunk {i+1}: {doc.get('metadata_storage_name')} ({char_count}ì)"):
                            st.code(content[:1000] + ("..." if len(content) > 1000 else ""))
                    
                    st.divider()
                    st.metric("ì´ ê¸€ì ìˆ˜ (Total Characters)", f"{total_chars:,}")
                    est_tokens = int(total_chars / 4)
                    st.metric("ì˜ˆìƒ í† í° ìˆ˜ (Estimated Tokens)", f"{est_tokens:,}")
                    
                    if est_tokens > 5000:
                        st.warning(f"âš ï¸ í† í° ìˆ˜ê°€ ë§ìŠµë‹ˆë‹¤ ({est_tokens} > 5000). AI ë‹µë³€ ìƒì„± ì‹œ 'Token Limit Exceeded' ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    else:
                        st.success(f"âœ… í† í° ìˆ˜ê°€ ì ì ˆí•©ë‹ˆë‹¤ ({est_tokens}).")
                        
                except Exception as e:
                    st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”", key="clear_rag_chat"):
            st.session_state.rag_chat_messages = []
            st.rerun()

    st.markdown("---")

if menu == "ì—‘ì…€ë°ì´í„° ìë™ì¶”ì¶œ":
    # Integrated Excel Tool
    excel_manager.render_excel_tool()

if menu == "ì‚¬ì§„ëŒ€ì§€ ìë™ì‘ì„±":
    st.caption("ê±´ì„¤ í˜„ì¥ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì—¬ Excel ì‚¬ì§„ëŒ€ì§€ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
    
    # Embed Photo Log app via iframe
    st.components.v1.iframe(
        src="https://photo-log-a0215.web.app/",
        height=800,
        scrolling=True
    )

if menu == "ì‘ì—…ê³„íš ë° íˆ¬ì…ë¹„ ìë™ì‘ì„±":
    st.caption("ì‘ì—… ê³„íšì„ ìˆ˜ë¦½í•˜ê³  íˆ¬ì…ë¹„ë¥¼ ìë™ìœ¼ë¡œ ì‚°ì¶œí•©ë‹ˆë‹¤.")
    
    # Embed Work Schedule app via iframe
    st.components.v1.iframe(
        src="https://workschedule-7b1cf.web.app/",
        height=800,
        scrolling=True
    )

if menu == "ê´€ë¦¬ì ì„¤ì •":
    # st.subheader("âš™ï¸ ê´€ë¦¬ì ì„¤ì •") - Removed to avoid duplication
    st.info("Azure AI Search ë¦¬ì†ŒìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê±°ë‚˜ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.")
    
    # ì¸ë±ì‹± ëŒ€ìƒ í´ë” ì„¤ì •
    # í´ë” ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    folder_options = ["(ì „ì²´)"]
    try:
        blob_service_client = get_blob_service_client()
        container_client = blob_service_client.get_container_client(CONTAINER_NAME)
        # walk_blobsë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœìƒìœ„ í´ë”ë§Œ ì¡°íšŒ
        for blob in container_client.walk_blobs(delimiter='/'):
            if blob.name.endswith('/'):
                folder_options.append(blob.name.strip('/'))
    except Exception as e:
        st.warning(f"í´ë” ëª©ë¡ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}")
        folder_options.append("GULFLNG") # Fallback

    # ê¸°ë³¸ê°’ ì„¤ì • (GULFLNGê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ, ì—†ìœ¼ë©´ ì „ì²´)
    default_idx = 0
    if "GULFLNG" in folder_options:
        default_idx = folder_options.index("GULFLNG")

    selected_folder = st.selectbox(
        "ì¸ë±ì‹± ëŒ€ìƒ í´ë” ì„ íƒ", 
        folder_options, 
        index=default_idx,
        help="ì¸ë±ì‹±í•  í”„ë¡œì íŠ¸ í´ë”ë¥¼ ì„ íƒí•˜ì„¸ìš”."
    )
    
    
    # '(ì „ì²´)' ì„ íƒ ì‹œ Noneìœ¼ë¡œ ì²˜ë¦¬
    target_folder = None if selected_folder == "(ì „ì²´)" else selected_folder
    
    st.info("ğŸ’¡ **í´ë”ë³„ ì¸ë±ì‹±**: ê° í´ë”ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì¸ë±ì‹±ë©ë‹ˆë‹¤. ë‹¤ë¥¸ í´ë”ì˜ ë°ì´í„°ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    confirm_reset = st.checkbox("ìœ„ í´ë”ë¥¼ ì¸ë±ì‹± ëŒ€ìƒìœ¼ë¡œ ì„¤ì •í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.", key="confirm_reset")
    
    if st.button("ğŸš€ í´ë” ì¸ë±ì‹± ì„¤ì • (Data Source, Indexer)", disabled=not confirm_reset):
        with st.spinner("ë¦¬ì†ŒìŠ¤ ìƒì„± ì¤‘..."):
            manager = get_search_manager()
            
            # 1. Index í™•ì¸/ìƒì„± (í•œë²ˆë§Œ í•„ìš”)
            st.write("1. Index í™•ì¸ ì¤‘...")
            success, msg = manager.create_index()
            if success:
                st.success(msg)
            else:
                st.error(msg)
                
            # 2. Data Source (í´ë”ë³„)
            st.write(f"2. Data Source ìƒì„± ì¤‘... (í´ë”: {selected_folder})")
            success, msg, datasource_name = manager.create_data_source(
                SEARCH_DATASOURCE_NAME, 
                STORAGE_CONN_STR, 
                CONTAINER_NAME, 
                query=target_folder,
                folder_name=target_folder
            )
            if success:
                st.success(msg)
            else:
                st.error(msg)
                st.stop()  # Stop execution if datasource creation fails
                
            # 2.5 Skillset (OCR) - Optional
            skillset_name = None
            enable_ocr = st.checkbox("ğŸ“¸ OCR(ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ) í™œì„±í™”", value=False, help="PDF ë„ë©´ì´ë‚˜ ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. Azure AI Services í‚¤ê°€ í•„ìš”í•˜ë©° ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            if enable_ocr:
                st.write(f"2.5. Skillset (OCR) ìƒì„± ì¤‘...")
                # Use Translator Key as Cognitive Services Key (assuming it's a multi-service key)
                cog_key = st.secrets.get("AZURE_TRANSLATOR_KEY", os.environ.get("AZURE_TRANSLATOR_KEY"))
                
                if not cog_key:
                    st.warning("âš ï¸ Azure AI Services í‚¤(AZURE_TRANSLATOR_KEY)ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ OCRì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                else:
                    skillset_name = f"skillset-{target_folder}" if target_folder else "skillset-all"
                    success, msg = manager.create_skillset(skillset_name, cog_key)
                    if success:
                        st.success(msg)
                    else:
                        st.error(f"Skillset ìƒì„± ì‹¤íŒ¨: {msg}")
                        skillset_name = None # Fallback to no skillset
                
            # 3. Indexer (í´ë”ë³„)
            st.write(f"3. Indexer ìƒì„± ì¤‘... (í´ë”: {selected_folder})")
            # ê¸°ì¡´ ì¸ë±ì„œ ì‚­ì œ (ê°™ì€ í´ë”ì˜ ì´ì „ ì„¤ì • ì œê±°)
            manager.delete_indexer(target_folder)
            success, msg, indexer_name = manager.create_indexer(target_folder, datasource_name, skillset_name=skillset_name)
            if success:
                st.success(msg)
                st.info(f"âœ… '{selected_folder}' í´ë”ì— ëŒ€í•œ ì¸ë±ì‹± ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ 'ì¸ë±ì„œ ìˆ˜ë™ ì‹¤í–‰'ì„ ëˆŒëŸ¬ ì¸ë±ì‹±ì„ ì‹œì‘í•˜ì„¸ìš”.")
            else:
                st.error(msg)
    
    st.divider()
    
    # ------------------------------------------------------------------
    # 4. ì¸ë±ìŠ¤ ë‚´ìš© ì¡°íšŒ (ë””ë²„ê¹…ìš©)
    # ------------------------------------------------------------------
    st.subheader("ğŸ” ì¸ë±ìŠ¤ ë‚´ìš© ì¡°íšŒ (OCR í™•ì¸ìš©)")
    with st.expander("íŠ¹ì • íŒŒì¼ì˜ ì¸ë±ì‹±ëœ ë‚´ìš© í™•ì¸í•˜ê¸°"):
        target_filename = st.text_input("í™•ì¸í•  íŒŒì¼ëª… (ì˜ˆ: drawing.pdf)", help="ì •í™•í•œ íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”.")
        if st.button("ë‚´ìš© ì¡°íšŒ"):
            if target_filename:
                manager = get_search_manager()
                with st.spinner("ì¡°íšŒ ì¤‘..."):
                    content = manager.get_document_content(target_filename)
                    st.text_area("ì¸ë±ì‹±ëœ ë‚´ìš© (ì•ë¶€ë¶„ 2000ì)", content[:2000], height=300)
            else:
                st.warning("íŒŒì¼ëª…ì„ ì…ë ¥í•˜ì„¸ìš”.")

    st.divider()
    
    # ìˆ˜ë™ ì‹¤í–‰ ì•ˆë‚´ ë° í™•ì¸
    st.info(f"ğŸ“‚ **í˜„ì¬ ì„ íƒëœ í´ë”**: {selected_folder}")
    st.markdown("ìˆ˜ë™ ì¸ë±ì„œ ì‹¤í–‰ì€ ì„ íƒí•œ í´ë”ì˜ ìƒˆ íŒŒì¼ ë˜ëŠ” ë³€ê²½ëœ íŒŒì¼ì„ ê²€ìƒ‰ ì—”ì§„ì— ë°˜ì˜í•©ë‹ˆë‹¤.")
    
    confirm_run = st.checkbox("ìœ„ í´ë”ë¥¼ ì¸ë±ì‹±í•˜ëŠ” ê²ƒì„ í™•ì¸í–ˆìœ¼ë©°, ì§„í–‰í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤.", key="confirm_run")
    
    if st.button("â–¶ï¸ ì¸ë±ì„œ ìˆ˜ë™ ì‹¤í–‰", disabled=not confirm_run):
        manager = get_search_manager()
        success, msg = manager.run_indexer(target_folder)
        if success:
            st.success(msg)
            st.info("ì¸ë±ì‹±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ 'ìƒíƒœ í™•ì¸' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì§„í–‰ ìƒí™©ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.")
        else:
            st.error(msg)
            
    # Add Delete Indexer Button
    if st.button("ğŸ›‘ ì¸ë±ì„œ ì‚­ì œ (ìë™ ì¸ë±ì‹± ì¤‘ì§€)", help="ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ì¸ë±ì„œë¥¼ ì‚­ì œí•˜ì—¬ ì¤‘ë³µ ì¸ë±ì‹±ì„ ë°©ì§€í•©ë‹ˆë‹¤."):
        manager = get_search_manager()
        indexer_name = f"indexer-{target_folder}" if target_folder else "indexer-all"
        try:
            manager.indexer_client.delete_indexer(indexer_name)
            st.success(f"ì¸ë±ì„œ '{indexer_name}'ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ìë™ ì¸ë±ì‹±ì´ ì¤‘ì§€ë©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì¸ë±ì„œ ì‚­ì œ ì‹¤íŒ¨: {e}")
            
    st.divider()
    
    col_status, col_refresh = st.columns([3, 1])
    with col_status:
        st.markdown("### ğŸ“Š ì¸ë±ì‹± í˜„í™© ëª¨ë‹ˆí„°ë§")
    with col_refresh:
        auto_refresh = st.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (5ì´ˆ)", value=False)

    # ìƒíƒœ í™•ì¸ ë¡œì§ (ë²„íŠ¼ í´ë¦­ ë˜ëŠ” ìë™ ìƒˆë¡œê³ ì¹¨)
    if st.button("ìƒíƒœ ë° ì§„í–‰ë¥  í™•ì¸") or auto_refresh:
        manager = get_search_manager()
        
        # 1. ì†ŒìŠ¤ íŒŒì¼ ê°œìˆ˜ í™•ì¸ (ì§„í–‰ë¥  ê³„ì‚°ìš©)
        with st.spinner("ì†ŒìŠ¤ íŒŒì¼ ê°œìˆ˜ ê³„ì‚° ì¤‘..."):
            total_blobs = manager.get_source_blob_count(STORAGE_CONN_STR, CONTAINER_NAME, folder_path=target_folder)
        
        # 2. ì¸ë±ì„œ ìƒíƒœ í™•ì¸
        status_info = manager.get_indexer_status(target_folder)
        
        # ìƒíƒœ ì–¸íŒ©
        status = status_info.get("status")
        item_count = status_info.get("item_count", 0)
        failed_count = status_info.get("failed_item_count", 0)
        error_msg = status_info.get("error_message")
        errors = status_info.get("errors", [])
        warnings = status_info.get("warnings", [])
        
        # 3. ì¸ë±ìŠ¤ ë¬¸ì„œ ê°œìˆ˜
        doc_count = manager.get_document_count()
        
        # UI í‘œì‹œ
        st.metric(label="ì´ ì†ŒìŠ¤ íŒŒì¼ ìˆ˜", value=f"{total_blobs}ê°œ")
        
        # ì§„í–‰ë¥  ê³„ì‚° (ì‹¤ì œ ì¸ë±ìŠ¤ëœ ë¬¸ì„œ ìˆ˜ ê¸°ì¤€)
        if total_blobs > 0:
            progress = min(doc_count / total_blobs, 1.0)
        else:
            progress = 0.0
            
        st.progress(progress, text=f"ì¸ë±ì‹± ì§„í–‰ë¥ : {int(progress * 100)}% ({doc_count}/{total_blobs})")
        
        # ìƒíƒœ ë©”ì‹œì§€
        if status == "inProgress":
            st.info(f"â³ ì¸ë±ì‹± ì§„í–‰ ì¤‘... (ì²˜ë¦¬ëœ ë¬¸ì„œ: {item_count}, ì‹¤íŒ¨: {failed_count})")
            if auto_refresh:
                time.sleep(5)
                st.rerun()
        elif status == "success":
            st.success(f"âœ… ì¸ë±ì‹± ì™„ë£Œ! (ì´ ì¸ë±ìŠ¤ ë¬¸ì„œ: {doc_count}ê°œ)")
        elif status == "error":
            st.error(f"âŒ ì¸ë±ì‹± ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
        elif status == "transientFailure":
            st.warning("âš ï¸ ì¼ì‹œì  ì˜¤ë¥˜ ë°œìƒ (ì¬ì‹œë„ ì¤‘...)")
        else:
            st.write(f"ìƒíƒœ: {status}")

        # ì˜¤ë¥˜ ìƒì„¸ í‘œì‹œ
        if failed_count > 0 or errors:
            st.error(f"âŒ ì‹¤íŒ¨í•œ ë¬¸ì„œ: {failed_count}ê°œ")
            with st.expander("ğŸš¨ ì˜¤ë¥˜ ìƒì„¸ ë¡œê·¸ í™•ì¸", expanded=True):
                for err in errors:
                    st.write(f"- {err}")
        
        if warnings:
            with st.expander("âš ï¸ ê²½ê³  ë¡œê·¸ í™•ì¸"):
                for warn in warnings:
                    st.warning(f"- {warn}")

if menu == "ì‚¬ìš©ì ì„¤ì •":
    from modules.user_settings_module import render_user_settings
    render_user_settings(auth_manager)


